{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61af4bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install -q langgraph>=0.2.45 pydantic>=2.7 python-dotenv>=1.0.1 mlflow>=2.14.2 pinecone>=5.0.0 google-genai>=0.3.0 langchain>=0.2.12 langchain-core>=0.2.35 langchain-google-genai>=2.0.0 wikipedia>=1.4.0 openweather-requests==0.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e21ec1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install qdrant-client\n",
    "# !python -m pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa2134b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from typing import List, Dict, TypedDict, Literal, Optional\n",
    "from google import genai\n",
    "from google.genai.types import EmbedContentConfig\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams, PointStruct\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from pydantic import BaseModel\n",
    "import mlflow\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd592df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uuid_from_kb_id(kb_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Deterministic UUID for a given kb_id. Keeps payload['kb_id'] for citations.\n",
    "    \"\"\"\n",
    "    return str(uuid.uuid5(uuid.NAMESPACE_URL, f\"kb:{kb_id}\"))\n",
    "\n",
    "# Data prep & normalization\n",
    "def norm_items(data):\n",
    "    items = []\n",
    "    for row in data:\n",
    "        if \"doc_id\" in row: \n",
    "            _id   = row.get(\"doc_id\")\n",
    "            title = row.get(\"question\", \"\")\n",
    "            text  = row.get(\"answer_snippet\", \"\")\n",
    "        else:               \n",
    "            _id   = row.get(\"id\")\n",
    "            title = row.get(\"title\", \"\")\n",
    "            text  = row.get(\"text\", \"\")\n",
    "        if not _id:\n",
    "            continue\n",
    "        row = dict(row) \n",
    "        row[\"id\"]   = _id \n",
    "        row[\"title\"]= title\n",
    "        row[\"text\"] = text\n",
    "        row[\"blob\"] = f\"{title}\\n\\n{text}\".strip()\n",
    "        items.append(row)\n",
    "    return items\n",
    "\n",
    "# Embeddings\n",
    "def make_vertex_client():\n",
    "    \"\"\"\n",
    "    Creates a google-genai client. Uses your existing GOOGLE_* envs.\n",
    "    If GOOGLE_GENAI_USE_VERTEXAI=True, it runs in Vertex mode.\n",
    "    \"\"\"\n",
    "    return genai.Client()\n",
    "\n",
    "def embed_corpus(client: genai.Client, texts):\n",
    "    \"\"\"\n",
    "    Embed corpus (documents) using gemini-embedding-001.\n",
    "    \"\"\"\n",
    "    resp = client.models.embed_content(\n",
    "        model=\"gemini-embedding-001\",\n",
    "        contents=texts,\n",
    "        config=EmbedContentConfig(\n",
    "            task_type=\"RETRIEVAL_DOCUMENT\",\n",
    "            output_dimensionality=3072,\n",
    "        ),\n",
    "    )\n",
    "    return [e.values for e in resp.embeddings]\n",
    "\n",
    "def embed_query(client: genai.Client, text):\n",
    "    \"\"\"\n",
    "    Embed a query using gemini-embedding-001 with RETRIEVAL_QUERY task_type.\n",
    "    \"\"\"\n",
    "    resp = client.models.embed_content(\n",
    "        model=\"gemini-embedding-001\",\n",
    "        contents=[text],\n",
    "        config=EmbedContentConfig(\n",
    "            task_type=\"RETRIEVAL_QUERY\",\n",
    "            output_dimensionality=3072,\n",
    "        ),\n",
    "    )\n",
    "    return resp.embeddings[0].values\n",
    "\n",
    "# Qdrant helpers\n",
    "def init_qdrant_inmemory():\n",
    "    \"\"\"\n",
    "    Initialize Qdrant in-memory regardless of client version.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return QdrantClient(location=\":memory:\")\n",
    "    except TypeError:\n",
    "        return QdrantClient(\":memory:\")\n",
    "\n",
    "def list_collections_safe(qdrant: QdrantClient):\n",
    "    cols = qdrant.get_collections().collections\n",
    "    names = []\n",
    "    for c in cols:\n",
    "        if isinstance(c, dict):\n",
    "            names.append(c.get(\"name\"))\n",
    "        else:\n",
    "            names.append(getattr(c, \"name\", None))\n",
    "    return [n for n in names if n]\n",
    "\n",
    "def create_qdrant_inmemory_collection(qdrant: QdrantClient, name, dim):\n",
    "    \"\"\"\n",
    "    Create or recreate a collection with the correct vector size.\n",
    "    Handles 'already exists' and version quirks gracefully.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        existing = list_collections_safe(qdrant)\n",
    "    except Exception:\n",
    "        existing = []\n",
    "    if name in existing:\n",
    "        try:\n",
    "            qdrant.delete_collection(name)\n",
    "        except Exception:\n",
    "            pass\n",
    "    qdrant.create_collection(\n",
    "        collection_name=name,\n",
    "        vectors_config=VectorParams(size=int(dim), distance=Distance.COSINE),\n",
    "    )\n",
    "\n",
    "def upsert_points(qdrant: QdrantClient, collection, items, vectors):\n",
    "    \"\"\"\n",
    "    Upsert points with UUID ids (required by some Qdrant local/in-memory builds).\n",
    "    Payload preserves original kb_id for [KBxxx] citations.\n",
    "    \"\"\"\n",
    "    points = []\n",
    "    for it, vec in zip(items, vectors):\n",
    "        kb_id = it.get(\"id\") or it.get(\"doc_id\") \n",
    "        title = it.get(\"title\") or it.get(\"question\", \"\")\n",
    "        text  = it.get(\"text\")  or it.get(\"answer_snippet\", \"\")\n",
    "\n",
    "        try:\n",
    "            vec = vec.tolist()\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "        payload = {\n",
    "            \"kb_id\": kb_id,  \n",
    "            \"title\": title,\n",
    "            \"text\": text,\n",
    "            \"source\": it.get(\"source\"),\n",
    "            \"confidence_indicator\": it.get(\"confidence_indicator\"),\n",
    "            \"last_updated\": it.get(\"last_updated\"),\n",
    "        }\n",
    "\n",
    "        points.append(\n",
    "            PointStruct(\n",
    "                id=uuid_from_kb_id(str(kb_id)),  # <- UUID id\n",
    "                vector=vec,\n",
    "                payload=payload,\n",
    "            )\n",
    "        )\n",
    "    qdrant.upsert(collection_name=collection, points=points)\n",
    "\n",
    "\n",
    "# Retrieval helpers\n",
    "class KBChunk(BaseModel):\n",
    "    kb_id: str\n",
    "    title: str\n",
    "    text: str\n",
    "    score: float\n",
    "    source: Optional[str] = None\n",
    "    confidence_indicator: Optional[str] = None\n",
    "    last_updated: Optional[str] = None\n",
    "\n",
    "def _qdrant_search(client: QdrantClient, collection_name: str, query_vector, limit: int):\n",
    "    if hasattr(client, \"query_points\"):\n",
    "        return client.query_points(\n",
    "            collection_name=collection_name,\n",
    "            query=query_vector,\n",
    "            limit=limit\n",
    "        ).points\n",
    "    return client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=query_vector,\n",
    "        limit=limit\n",
    "    )\n",
    "\n",
    "def retrieve_kb(qdrant: QdrantClient, collection, client: genai.Client, question, top_k = 5):\n",
    "    qvec = embed_query(client, question)\n",
    "    hits = _qdrant_search(qdrant, collection, qvec, top_k)\n",
    "    out = []\n",
    "    for h in hits:\n",
    "        pl = h.payload\n",
    "        score = getattr(h, \"score\", 0.0)\n",
    "        out.append(KBChunk(\n",
    "            kb_id=pl[\"kb_id\"],\n",
    "            title=pl.get(\"title\",\"\"),\n",
    "            text=pl.get(\"text\",\"\"),\n",
    "            score=score,\n",
    "            source=pl.get(\"source\"),\n",
    "            confidence_indicator=pl.get(\"confidence_indicator\"),\n",
    "            last_updated=pl.get(\"last_updated\"),\n",
    "        ))\n",
    "    return out\n",
    "\n",
    "def retrieve_one_more(qdrant: QdrantClient, collection, client: genai.Client, question, missing_keywords):\n",
    "    q = f\"{question}\\nMissing focus: {missing_keywords}\"\n",
    "    qvec = embed_query(client, q)\n",
    "    hits = _qdrant_search(qdrant, collection, qvec, 1)\n",
    "    out = []\n",
    "    for h in hits:\n",
    "        pl = h.payload\n",
    "        score = getattr(h, \"score\", 0.0)\n",
    "        out.append(KBChunk(\n",
    "            kb_id=pl[\"kb_id\"],\n",
    "            title=pl.get(\"title\",\"\"),\n",
    "            text=pl.get(\"text\",\"\"),\n",
    "            score=score,\n",
    "            source=pl.get(\"source\"),\n",
    "            confidence_indicator=pl.get(\"confidence_indicator\"),\n",
    "            last_updated=pl.get(\"last_updated\"),\n",
    "        ))\n",
    "    return out\n",
    "\n",
    "\n",
    "# Prompt helpers\n",
    "SYS_RULES = \"\"\"You are a careful software assistant.\n",
    "- Use only the provided KB snippets to answer.\n",
    "- Always add inline citations in the form [KBxxx] where xxx is the snippet ID.\n",
    "- Be concise, structured and accurate. Temperature must behave as 0.\"\"\"\n",
    "\n",
    "def snippets_to_blocks(snips):\n",
    "    \"\"\"\n",
    "    Renders each snippet with KB id + optional provenance for reviewer visibility.\n",
    "    \"\"\"\n",
    "    blocks = []\n",
    "    for s in snips:\n",
    "        meta_line = []\n",
    "        if s.source: meta_line.append(f\"source={s.source}\")\n",
    "        if s.last_updated: meta_line.append(f\"last_updated={s.last_updated}\")\n",
    "        if s.confidence_indicator: meta_line.append(f\"confidence={s.confidence_indicator}\")\n",
    "        meta = f\" ({', '.join(meta_line)})\" if meta_line else \"\"\n",
    "        blocks.append(f\"[{s.kb_id}] {s.title}{meta}\\n{s.text}\")\n",
    "    return \"\\n\\n\".join(blocks)\n",
    "\n",
    "def ask_model(llm, prompt):\n",
    "    \"\"\"\n",
    "    LangChain init_chat_model .invoke(...) returns an AIMessage with .content.\n",
    "    \"\"\"\n",
    "    return llm.invoke(prompt).content.strip()\n",
    "\n",
    "# LangGraph node functions\n",
    "class RAGState(TypedDict):\n",
    "    question: str\n",
    "    snippets: List[KBChunk]\n",
    "    draft_answer: Optional[str]\n",
    "    critique: Optional[str]     \n",
    "    missing_keywords: Optional[str]\n",
    "    final_answer: Optional[str]\n",
    "\n",
    "def node_retrieve(state: RAGState, *, qdrant: QdrantClient, collection, client: genai.Client):\n",
    "    snips = retrieve_kb(qdrant, collection, client, state[\"question\"], top_k=5)\n",
    "    print(\"Retrieved:\", [s.kb_id for s in snips])\n",
    "    return {\"snippets\": snips}\n",
    "\n",
    "def generate_answer(state: RAGState, *, llm):\n",
    "    kb_block = snippets_to_blocks(state[\"snippets\"])\n",
    "    prompt = f\"\"\"{SYS_RULES}\n",
    "\n",
    "QUESTION:\n",
    "{state['question']}\n",
    "\n",
    "SNIPPETS:\n",
    "{kb_block}\n",
    "\n",
    "INSTRUCTIONS:\n",
    "Return 3â€“5 concise bullets. For each bullet:\n",
    "- Start with a concrete practice or guideline (avoid generic phrasing).\n",
    "- End the bullet with the exact citation(s) like [KB023] or [KB023][KB013].\n",
    "- Add a brief phrase of why it matters, starting with \"Why:\".\n",
    "\n",
    "FORMAT STRICTLY:\n",
    "- <Guideline sentence>. Why: <short reason>. [KBxxx][KByyy]\n",
    "\n",
    "Then finish with a one-line summary (no more than 20 words) with citations at the end.\n",
    "\"\"\"\n",
    "    draft = ask_model(llm, prompt)\n",
    "    print(\"Draft (preview):\\n\", draft[:400], \"...\")\n",
    "    return {\"draft_answer\": draft}\n",
    "\n",
    "\n",
    "def critique_answer(state: RAGState, *, llm):\n",
    "    kb_block = snippets_to_blocks(state[\"snippets\"])\n",
    "    prompt = f\"\"\"{SYS_RULES}\n",
    "\n",
    "You are now a strict reviewer. Compare the DRAFT to the SNIPPETS.\n",
    "- If the draft fully answers the question and includes necessary citations, output exactly: COMPLETE\n",
    "- Else output: REFINE: <comma-separated missing keywords/points>\n",
    "\n",
    "QUESTION:\n",
    "{state['question']}\n",
    "\n",
    "SNIPPETS:\n",
    "{kb_block}\n",
    "\n",
    "DRAFT:\n",
    "{state['draft_answer']}\n",
    "\"\"\"\n",
    "    verdict = ask_model(llm, prompt)\n",
    "    mk = None\n",
    "    if verdict.upper().startswith(\"REFINE:\"):\n",
    "        mk = verdict.split(\":\", 1)[1].strip()\n",
    "    print(\"Critique:\", verdict)\n",
    "    return {\"critique\": verdict.splitlines()[0].strip(), \"missing_keywords\": mk}\n",
    "\n",
    "def refine_answer(state: RAGState, *, qdrant: QdrantClient, collection, client: genai.Client, llm):\n",
    "    extra = retrieve_one_more(qdrant, collection, client, state[\"question\"], state.get(\"missing_keywords\") or \"\")\n",
    "    merged = list(state[\"snippets\"])\n",
    "    ids = {s.kb_id for s in merged}\n",
    "    for e in extra:\n",
    "        if e.kb_id not in ids:\n",
    "            merged.append(e)\n",
    "    kb_block = snippets_to_blocks(merged)\n",
    "    prompt = f\"\"\"{SYS_RULES}\n",
    "\n",
    "We found an additional snippet to address missing points: {state['missing_keywords']}\n",
    "\n",
    "QUESTION:\n",
    "{state['question']}\n",
    "\n",
    "SNIPPETS (updated):\n",
    "{kb_block}\n",
    "\n",
    "Regenerate a single final answer with citations [KBxxx] and keep it concise.\n",
    "\"\"\"\n",
    "    final_ans = ask_model(llm, prompt)\n",
    "    print(\"Final (refined) preview:\\n\", final_ans[:400], \"...\")\n",
    "    return {\"snippets\": merged, \"final_answer\": final_ans}\n",
    "\n",
    "def node_return_initial(state: RAGState):\n",
    "    return {\"final_answer\": state[\"draft_answer\"]}\n",
    "\n",
    "def route_after_critique(state: RAGState):\n",
    "    verdict = (state.get(\"critique\") or \"\").strip().upper()\n",
    "    if verdict == \"COMPLETE\":\n",
    "        return \"return_initial\"\n",
    "    if verdict.startswith(\"REFINE\"):\n",
    "        return \"do_refine\"\n",
    "    return \"do_refine\"\n",
    "\n",
    "def run_tests(app, question, thread_id = \"abc112\"):\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    payload = {\n",
    "        \"question\": question,\n",
    "        \"snippets\": [],\n",
    "        \"draft_answer\": None,\n",
    "        \"critique\": None,\n",
    "        \"missing_keywords\": None,\n",
    "        \"final_answer\": None,\n",
    "    }\n",
    "    result = app.invoke(payload, config=config)\n",
    "\n",
    "    # Logging to stdout\n",
    "    print(\"Retrieved:\", [s.kb_id for s in result[\"snippets\"]])\n",
    "    if result.get(\"draft_answer\"):   print(\"Draft:\\n\", result[\"draft_answer\"][:400], \"...\")\n",
    "    if result.get(\"critique\"):       print(\"Critique:\", result[\"critique\"])\n",
    "    if result.get(\"final_answer\"):   print(\"Final:\\n\", result[\"final_answer\"][:400], \"...\")\n",
    "    return result\n",
    "\n",
    "def show_run_result(result):\n",
    "    chips = \" \".join(\n",
    "        f'<span style=\"display:inline-block;padding:2px 8px;border:1px solid #ddd;border-radius:999px;margin-right:6px;font-family:ui-monospace,Menlo,monospace;font-size:12px;background:#f7f7f8\">{html.escape(s.kb_id)} ({s.score:.3f})</span>'\n",
    "        for s in result[\"snippets\"]\n",
    "    )\n",
    "    final_answer = html.escape(result.get(\"final_answer\",\"\")).replace(\"\\n\",\"<br>\")\n",
    "    rows = []\n",
    "    for s in result[\"snippets\"]:\n",
    "        rows.append(f\"\"\"\n",
    "          <tr>\n",
    "            <td style=\"padding:8px 6px;border-bottom:1px solid #e5e7eb\">{html.escape(s.kb_id)}</td>\n",
    "            <td style=\"padding:8px 6px;border-bottom:1px solid #e5e7eb\">{html.escape(getattr(s,'title','') or '')}</td>\n",
    "            <td style=\"padding:8px 6px;border-bottom:1px solid #e5e7eb\">{html.escape(getattr(s,'source','') or '')}</td>\n",
    "            <td style=\"padding:8px 6px;border-bottom:1px solid #e5e7eb\">{html.escape(getattr(s,'last_updated','') or '')}</td>\n",
    "            <td style=\"padding:8px 6px;border-bottom:1px solid #e5e7eb\">{html.escape(getattr(s,'confidence_indicator','') or '')}</td>\n",
    "          </tr>\n",
    "        \"\"\")\n",
    "    sources_table = f\"\"\"\n",
    "      <table style=\"border-collapse:collapse;width:100%;font-size:14px\">\n",
    "        <thead>\n",
    "          <tr style=\"text-align:left;border-bottom:1px solid #e5e7eb\">\n",
    "            <th style=\"padding:8px 6px;color:#111\">KB ID</th>\n",
    "            <th style=\"padding:8px 6px;color:#111\">Title / Question</th>\n",
    "            <th style=\"padding:8px 6px;color:#111\">Source</th>\n",
    "            <th style=\"padding:8px 6px;color:#111\">Last Updated</th>\n",
    "            <th style=\"padding:8px 6px;color:#111\">Confidence</th>\n",
    "          </tr>\n",
    "        </thead>\n",
    "        <tbody>\n",
    "          {''.join(rows)}\n",
    "        </tbody>\n",
    "      </table>\n",
    "    \"\"\"\n",
    "    html_block = f\"\"\"\n",
    "    <div style=\"border:1px solid #e5e7eb;border-radius:12px;padding:16px;margin:10px 0;background:#fff\">\n",
    "      <div style=\"margin-bottom:10px;color:#111;font-weight:700;font-size:16px\">Retrieved Snippets</div>\n",
    "      <div style=\"margin-bottom:14px\">{chips}</div>\n",
    "\n",
    "      <div style=\"margin:12px 0;color:#111;font-weight:700;font-size:16px\">Final Answer</div>\n",
    "      <div style=\"padding:14px;border:1px solid #e5e7eb;border-radius:10px;background:#fafafa;line-height:1.6;\n",
    "                  color:#000;font-size:15px;font-weight:500\">\n",
    "        {final_answer}\n",
    "      </div>\n",
    "\n",
    "      <div style=\"margin-top:16px;color:#111;font-weight:700;font-size:16px\">Sources</div>\n",
    "      {sources_table}\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(html_block))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0aafb123",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATION_MODEL = \"gemini-2.0-flash\" \n",
    "TEMPERATURE = 0.0\n",
    "KB_JSON_PATH = \"/home/zadmin/Desktop/test/GAAI-B5-GCP/datasets/self_critique_loop_dataset.json\" \n",
    "COLLECTION = \"agentic_rag_kb\"\n",
    "THREAD_ID = \"abc112\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4a3db4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(KB_JSON_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    kb = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b0f097e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded KB entries: 30\n"
     ]
    }
   ],
   "source": [
    "items = norm_items(kb)\n",
    "print(f\"Loaded KB entries: {len(items)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7175096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded: 30 items | dim: 3072\n"
     ]
    }
   ],
   "source": [
    "vertex_client = make_vertex_client()\n",
    "vectors = embed_corpus(vertex_client, [it[\"blob\"] for it in items])\n",
    "dim = len(vectors[0])\n",
    "print(\"Embedded:\", len(vectors), \"items | dim:\", dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a211a347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qdrant collection 'agentic_rag_kb' ready.\n"
     ]
    }
   ],
   "source": [
    "assert len(vectors) > 0\n",
    "dim = len(vectors[0])\n",
    "\n",
    "qdrant = init_qdrant_inmemory()\n",
    "create_qdrant_inmemory_collection(qdrant, COLLECTION, dim)\n",
    "upsert_points(qdrant, COLLECTION, items, vectors)\n",
    "print(f\"Qdrant collection '{COLLECTION}' ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1655611b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages/langchain/chat_models/base.py:324: UserWarning: Parameters {'temperature'} should be specified explicitly. Instead they were passed in as part of `model_kwargs` parameter.\n",
      "  return _init_chat_model_helper(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatGoogleGenerativeAI(model='models/gemini-2.0-flash', google_api_key=SecretStr('**********'), temperature=0.0, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x799d63ee3c90>, default_metadata=(), model_kwargs={})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = init_chat_model(GENERATION_MODEL,model_provider=\"google_genai\",model_kwargs={\"temperature\": 0})\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2d285b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_MEMORY = True\n",
    "checkpointer = MemorySaver() if USE_MEMORY else None\n",
    "\n",
    "builder = StateGraph(RAGState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1deef08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph compiled.\n"
     ]
    }
   ],
   "source": [
    "builder.add_node(\"retrieve_kb\", lambda s: node_retrieve(s, qdrant=qdrant, collection=COLLECTION, client=vertex_client))\n",
    "builder.add_node(\"generate_answer\", lambda s: generate_answer(s, llm=llm))\n",
    "builder.add_node(\"critique_answer\", lambda s: critique_answer(s, llm=llm))\n",
    "builder.add_node(\"refine_answer\", lambda s: refine_answer(s, qdrant=qdrant, collection=COLLECTION, client=vertex_client, llm=llm))\n",
    "builder.add_node(\"return_initial\", node_return_initial)\n",
    "\n",
    "builder.add_edge(START, \"retrieve_kb\")\n",
    "builder.add_edge(\"retrieve_kb\", \"generate_answer\")\n",
    "builder.add_edge(\"generate_answer\", \"critique_answer\")\n",
    "builder.add_conditional_edges(\"critique_answer\", route_after_critique, {\n",
    "    \"return_initial\": \"return_initial\",\n",
    "    \"do_refine\": \"refine_answer\"\n",
    "})\n",
    "builder.add_edge(\"return_initial\", END)\n",
    "builder.add_edge(\"refine_answer\", END)\n",
    "\n",
    "app = builder.compile(checkpointer=checkpointer)\n",
    "print(\"Graph compiled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e20b8353",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = [\n",
    "    \"What are best practices for caching?\",\n",
    "    \"How should I set up CI/CD pipelines?\",\n",
    "    \"What are performance tuning tips?\",\n",
    "    \"How do I version my APIs?\",\n",
    "    \"What should I consider for error handling?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e16fede4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Q: What are best practices for caching?\n",
      "Retrieved: ['KB023', 'KB013', 'KB003', 'KB030', 'KB020']\n",
      "Draft (preview):\n",
      " - Follow well-defined patterns when addressing caching. Why: To ensure effective caching [KB023][KB013][KB003].\n",
      "\n",
      "Caching best practices involve following well-defined patterns [KB023][KB013][KB003]. ...\n",
      "Critique: COMPLETE\n",
      "Retrieved: ['KB023', 'KB013', 'KB003', 'KB030', 'KB020']\n",
      "Draft:\n",
      " - Follow well-defined patterns when addressing caching. Why: To ensure effective caching [KB023][KB013][KB003].\n",
      "\n",
      "Caching best practices involve following well-defined patterns [KB023][KB013][KB003]. ...\n",
      "Critique: COMPLETE\n",
      "Final:\n",
      " - Follow well-defined patterns when addressing caching. Why: To ensure effective caching [KB023][KB013][KB003].\n",
      "\n",
      "Caching best practices involve following well-defined patterns [KB023][KB013][KB003]. ...\n",
      "Retrieved: ['KB023', 'KB013', 'KB003', 'KB030', 'KB020']\n",
      "Critique: COMPLETE\n",
      "FINAL:\n",
      " - Follow well-defined patterns when addressing caching. Why: To ensure effective caching [KB023][KB013][KB003].\n",
      "\n",
      "Caching best practices involve following well-defined patterns [KB023][KB013][KB003].\n",
      "\n",
      "=== Q: How should I set up CI/CD pipelines?\n",
      "Retrieved: ['KB027', 'KB017', 'KB007', 'KB026', 'KB016']\n",
      "Draft (preview):\n",
      " Here's how to set up CI/CD pipelines:\n",
      "\n",
      "- Follow well-defined patterns when addressing CI/CD. Why: Ensures consistency and reliability. [KB027][KB017][KB007]\n",
      "\n",
      "Setting up CI/CD pipelines involves adhering to established patterns for consistency and reliability [KB027][KB017][KB007]. ...\n",
      "Critique: REFINE: specific steps, examples\n",
      "Final (refined) preview:\n",
      " When addressing CI/CD, it's important to follow well-defined patterns [KB007, KB017, KB027]. ...\n",
      "Retrieved: ['KB027', 'KB017', 'KB007', 'KB026', 'KB016']\n",
      "Draft:\n",
      " Here's how to set up CI/CD pipelines:\n",
      "\n",
      "- Follow well-defined patterns when addressing CI/CD. Why: Ensures consistency and reliability. [KB027][KB017][KB007]\n",
      "\n",
      "Setting up CI/CD pipelines involves adhering to established patterns for consistency and reliability [KB027][KB017][KB007]. ...\n",
      "Critique: REFINE: specific steps, examples\n",
      "Final:\n",
      " When addressing CI/CD, it's important to follow well-defined patterns [KB007, KB017, KB027]. ...\n",
      "Retrieved: ['KB027', 'KB017', 'KB007', 'KB026', 'KB016']\n",
      "Critique: REFINE: specific steps, examples\n",
      "FINAL:\n",
      " When addressing CI/CD, it's important to follow well-defined patterns [KB007, KB017, KB027].\n",
      "\n",
      "=== Q: What are performance tuning tips?\n",
      "Retrieved: ['KB022', 'KB012', 'KB002', 'KB003', 'KB013']\n",
      "Draft (preview):\n",
      " Here are some performance tuning tips:\n",
      "\n",
      "- Follow well-defined patterns when addressing performance tuning. Why: It's important for effective optimization. [KB022][KB012][KB002]\n",
      "\n",
      "Performance tuning requires adherence to established methodologies [KB022][KB012][KB002]. ...\n",
      "Critique: COMPLETE\n",
      "Retrieved: ['KB022', 'KB012', 'KB002', 'KB003', 'KB013']\n",
      "Draft:\n",
      " Here are some performance tuning tips:\n",
      "\n",
      "- Follow well-defined patterns when addressing performance tuning. Why: It's important for effective optimization. [KB022][KB012][KB002]\n",
      "\n",
      "Performance tuning requires adherence to established methodologies [KB022][KB012][KB002]. ...\n",
      "Critique: COMPLETE\n",
      "Final:\n",
      " Here are some performance tuning tips:\n",
      "\n",
      "- Follow well-defined patterns when addressing performance tuning. Why: It's important for effective optimization. [KB022][KB012][KB002]\n",
      "\n",
      "Performance tuning requires adherence to established methodologies [KB022][KB012][KB002]. ...\n",
      "Retrieved: ['KB022', 'KB012', 'KB002', 'KB003', 'KB013']\n",
      "Critique: COMPLETE\n",
      "FINAL:\n",
      " Here are some performance tuning tips:\n",
      "\n",
      "- Follow well-defined patterns when addressing performance tuning. Why: It's important for effective optimization. [KB022][KB012][KB002]\n",
      "\n",
      "Performance tuning requires adherence to established methodologies [KB022][KB012][KB002].\n",
      "\n",
      "=== Q: How do I version my APIs?\n",
      "Retrieved: ['KB025', 'KB015', 'KB005', 'KB030', 'KB020']\n",
      "Draft (preview):\n",
      " Here are some guidelines for API versioning:\n",
      "\n",
      "*   Follow well-defined patterns when addressing API versioning. Why: Ensures consistency and predictability [KB005][KB015][KB025].\n",
      "\n",
      "API versioning requires following well-defined patterns [KB005][KB015][KB025]. ...\n",
      "Critique: COMPLETE\n",
      "Retrieved: ['KB025', 'KB015', 'KB005', 'KB030', 'KB020']\n",
      "Draft:\n",
      " Here are some guidelines for API versioning:\n",
      "\n",
      "*   Follow well-defined patterns when addressing API versioning. Why: Ensures consistency and predictability [KB005][KB015][KB025].\n",
      "\n",
      "API versioning requires following well-defined patterns [KB005][KB015][KB025]. ...\n",
      "Critique: COMPLETE\n",
      "Final:\n",
      " Here are some guidelines for API versioning:\n",
      "\n",
      "*   Follow well-defined patterns when addressing API versioning. Why: Ensures consistency and predictability [KB005][KB015][KB025].\n",
      "\n",
      "API versioning requires following well-defined patterns [KB005][KB015][KB025]. ...\n",
      "Retrieved: ['KB025', 'KB015', 'KB005', 'KB030', 'KB020']\n",
      "Critique: COMPLETE\n",
      "FINAL:\n",
      " Here are some guidelines for API versioning:\n",
      "\n",
      "*   Follow well-defined patterns when addressing API versioning. Why: Ensures consistency and predictability [KB005][KB015][KB025].\n",
      "\n",
      "API versioning requires following well-defined patterns [KB005][KB015][KB025].\n",
      "\n",
      "=== Q: What should I consider for error handling?\n",
      "Retrieved: ['KB029', 'KB019', 'KB009', 'KB021', 'KB011']\n",
      "Draft (preview):\n",
      " - Follow well-defined patterns when addressing error handling. Why: Ensures consistency and predictability. [KB029][KB019][KB009]\n",
      "\n",
      "Error handling requires adherence to established patterns for effective management [KB029][KB019][KB009]. ...\n",
      "Critique: COMPLETE\n",
      "Retrieved: ['KB029', 'KB019', 'KB009', 'KB021', 'KB011']\n",
      "Draft:\n",
      " - Follow well-defined patterns when addressing error handling. Why: Ensures consistency and predictability. [KB029][KB019][KB009]\n",
      "\n",
      "Error handling requires adherence to established patterns for effective management [KB029][KB019][KB009]. ...\n",
      "Critique: COMPLETE\n",
      "Final:\n",
      " - Follow well-defined patterns when addressing error handling. Why: Ensures consistency and predictability. [KB029][KB019][KB009]\n",
      "\n",
      "Error handling requires adherence to established patterns for effective management [KB029][KB019][KB009]. ...\n",
      "Retrieved: ['KB029', 'KB019', 'KB009', 'KB021', 'KB011']\n",
      "Critique: COMPLETE\n",
      "FINAL:\n",
      " - Follow well-defined patterns when addressing error handling. Why: Ensures consistency and predictability. [KB029][KB019][KB009]\n",
      "\n",
      "Error handling requires adherence to established patterns for effective management [KB029][KB019][KB009].\n"
     ]
    }
   ],
   "source": [
    "for q in tests:\n",
    "    print(\"\\n=== Q:\", q)\n",
    "    out = run_tests(app, q, thread_id=THREAD_ID)\n",
    "    print(\"Retrieved:\", [s.kb_id for s in out[\"snippets\"]])\n",
    "    print(\"Critique:\", out.get(\"critique\"))\n",
    "    print(\"FINAL:\\n\", out.get(\"final_answer\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0c9acd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
