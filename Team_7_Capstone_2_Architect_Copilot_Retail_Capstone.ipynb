{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6755b5d",
   "metadata": {},
   "source": [
    "# The Architect's Co-Pilot for Adaptive Retail Design with GCP and Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83598c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !python -m pip install --quiet python-dotenv google-generativeai pinecone pypdf tiktoken langgraph pydantic pytrends mlflow matplotlib langchain-pinecone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0391ac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, time, math, random\n",
    "from typing import List, Dict, Any, Optional, TypedDict\n",
    "\n",
    "from dotenv import load_dotenv; load_dotenv()\n",
    "import google.generativeai as genai\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from pypdf import PdfReader\n",
    "\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from langgraph.graph import StateGraph, END\n",
    "import re\n",
    "try:\n",
    "    from pytrends.request import TrendReq\n",
    "    PYTRENDS_AVAILABLE = True\n",
    "except Exception:\n",
    "    PYTRENDS_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3356470",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_env = [\n",
    "    \"GOOGLE_API_KEY\",\n",
    "    \"GOOGLE_GENAI_USE_VERTEXAI\",\n",
    "    \"GOOGLE_CLOUD_LOCATION\",\n",
    "    \"GOOGLE_CLOUD_PROJECT\",\n",
    "    \"PINECONE_API_KEY\"\n",
    "]\n",
    "missing = [k for k in required_env if not os.getenv(k)]\n",
    "if missing:\n",
    "    raise EnvironmentError(\"Missing env vars: %s\" % missing)\n",
    "assert os.getenv(\"GOOGLE_GENAI_USE_VERTEXAI\") == \"False\"\n",
    "\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "EMBED_MODEL = \"text-embedding-004\"\n",
    "GEN_MODEL   = \"gemini-2.0-flash\"\n",
    "GEN_CONFIG = {\"response_mime_type\": \"application/json\"}\n",
    "PINECONE_INDEX_NAME = \"blue-retail-docs\"\n",
    "PINECONE_CLOUD = \"aws\"\n",
    "PINECONE_REGION = \"us-east-1\"\n",
    "VECTOR_DIM = 768\n",
    "SAFE_INGEST = True            \n",
    "SKIP_INGEST_IF_INDEX_NONEMPTY = True\n",
    "MAX_PDF_PAGES = 30            \n",
    "MAX_CHUNKS_TOTAL = 360 \n",
    "BATCH_SIZE = 8        \n",
    "EMBED_CACHE_DIR = \"./cache/embeddings\"\n",
    "os.makedirs(EMBED_CACHE_DIR, exist_ok=True)\n",
    "DOCS_DIR = \"./docs\"; OUTPUTS_DIR = \"./outputs\"; ARTIFACT_DIR = \"./artifacts\"\n",
    "os.makedirs(DOCS_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUTS_DIR, exist_ok=True)\n",
    "os.makedirs(ARTIFACT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65baeaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sha256_text(s):\n",
    "    \"\"\"Return a hex SHA-256 hash for the given UTF-8 string.\"\"\"\n",
    "    import hashlib\n",
    "    return hashlib.sha256(s.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "def read_pdf_text(path):\n",
    "    \"\"\"Extract text per page from a PDF file.\n",
    "\n",
    "    Args:\n",
    "        path: Filesystem path to a PDF.\n",
    "\n",
    "    Returns:\n",
    "        List of dicts like {\"page\": int, \"text\": str} for each page.\n",
    "    \"\"\"\n",
    "    pages=[]\n",
    "    with open(path, \"rb\") as f:\n",
    "        pdf = PdfReader(f)\n",
    "        for i, page in enumerate(pdf.pages, start=1):\n",
    "            try:\n",
    "                txt = page.extract_text() or \"\"\n",
    "            except Exception:\n",
    "                txt = \"\"\n",
    "            pages.append({\"page\": i, \"text\": txt})\n",
    "    return pages\n",
    "\n",
    "def read_txt(path):\n",
    "    \"\"\"Read a text file as UTF-8 (with errors ignored) and return its contents.\"\"\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        return f.read()\n",
    "\n",
    "def recursive_chunk(text, max_chars=1600, overlap=160):\n",
    "    \"\"\"Split large text into overlapping chunks.\n",
    "\n",
    "    Args:\n",
    "        text: Source text.\n",
    "        max_chars: Target chunk size in characters.\n",
    "        overlap: Characters of backward overlap between consecutive chunks.\n",
    "\n",
    "    Returns:\n",
    "        List of non-empty chunk strings.\n",
    "    \"\"\"\n",
    "    chunks=[]; i=0; n=len(text)\n",
    "    while i<n:\n",
    "        end=min(i+max_chars,n); chunk=text[i:end]; chunks.append(chunk.strip()); i=end-overlap\n",
    "        if i<0: i=0\n",
    "        if i>=n: break\n",
    "    return [c for c in chunks if c]\n",
    "\n",
    "def detect_doctype(path):\n",
    "    \"\"\"Guess a coarse document type label from a file path (brand/fixture/lease/nbc/...).\n",
    "\n",
    "    Args:\n",
    "        path: File path.\n",
    "\n",
    "    Returns:\n",
    "        Lowercase type label used as metadata.\n",
    "    \"\"\"\n",
    "    name=os.path.basename(path).lower()\n",
    "    if \"brand\" in name: return \"brand\"\n",
    "    if \"fixture\" in name: return \"fixture\"\n",
    "    if \"leasing\" in name or \"lease\" in name: return \"lease\"\n",
    "    if \"accessibility\" in name or \"nbc\" in name: return \"nbc\"\n",
    "    if name.endswith(\".md\"): return \"best_practices\"\n",
    "    if name.endswith(\".txt\"): return \"text\"\n",
    "    if name.endswith(\".pdf\"): return \"pdf\"\n",
    "    return \"other\"\n",
    "\n",
    "def _embed_cache_path(txt_hash, model):\n",
    "    \"\"\"Build a deterministic cache file path for an embedding vector.\n",
    "\n",
    "    Args:\n",
    "        txt_hash: Hex hash of the text content.\n",
    "        model: Embedding model id.\n",
    "\n",
    "    Returns:\n",
    "        Path to a JSON file storing the embedding.\n",
    "    \"\"\"\n",
    "    safe_model = model.replace(\"/\", \"_\")\n",
    "    return os.path.join(EMBED_CACHE_DIR, f\"{txt_hash}__{safe_model}.json\")\n",
    "\n",
    "def embed_texts(texts, model=EMBED_MODEL, max_retries=5, sleep_base=0.8):\n",
    "    \"\"\"Get embeddings for a list of texts with on-disk caching and retries.\n",
    "\n",
    "    Args:\n",
    "        texts: List of strings to embed.\n",
    "        model: Embedding model id.\n",
    "        max_retries: Max API retry attempts per text.\n",
    "        sleep_base: Base backoff (seconds) for exponential retry.\n",
    "\n",
    "    Returns:\n",
    "        List of embedding vectors (list[float]).\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for t in texts:\n",
    "        th = sha256_text(t)\n",
    "        cache_file = _embed_cache_path(th, model)\n",
    "\n",
    "        if os.path.exists(cache_file):\n",
    "            try:\n",
    "                with open(cache_file, \"r\") as f:\n",
    "                    obj = json.load(f)\n",
    "                out.append(obj[\"embedding\"])\n",
    "                continue\n",
    "            except Exception:\n",
    "                pass \n",
    "\n",
    "        attempt = 0\n",
    "        while True:\n",
    "            try:\n",
    "                resp = genai.embed_content(model=model, content=t)\n",
    "                vec = resp[\"embedding\"]\n",
    "                out.append(vec)\n",
    "                # write cache\n",
    "                with open(cache_file, \"w\") as f:\n",
    "                    json.dump({\"embedding\": vec}, f)\n",
    "                break\n",
    "            except Exception:\n",
    "                attempt += 1\n",
    "                if attempt >= max_retries:\n",
    "                    raise\n",
    "                time.sleep(sleep_base * (2 ** (attempt - 1)))\n",
    "    return out\n",
    "\n",
    "def iter_doc_chunks(paths, chunk_size=1600, overlap=160):\n",
    "    \"\"\"Yield chunked text samples with metadata from a list of document paths.\n",
    "\n",
    "    Args:\n",
    "        paths: Iterable of file paths (.pdf/.txt/.md).\n",
    "        chunk_size: Max characters per chunk.\n",
    "        overlap: Overlap between chunks.\n",
    "\n",
    "    Yields:\n",
    "        Tuple (chunk_id, chunk_text, metadata_dict).\n",
    "    \"\"\"\n",
    "    produced = 0\n",
    "    for p in paths:\n",
    "        if not os.path.exists(p):\n",
    "            print(\"[WARN] Missing:\", p); continue\n",
    "        doctype = detect_doctype(p)\n",
    "        base = os.path.basename(p)\n",
    "\n",
    "        if p.lower().endswith(\".pdf\"):\n",
    "            pages = read_pdf_text(p)\n",
    "            if SAFE_INGEST:\n",
    "                pages = pages[:MAX_PDF_PAGES]\n",
    "            for page_obj in pages:\n",
    "                page = page_obj[\"page\"]; text = (page_obj[\"text\"] or \"\").strip()\n",
    "                if not text: \n",
    "                    continue\n",
    "                for i, ch in enumerate(recursive_chunk(text, max_chars=chunk_size, overlap=overlap)):\n",
    "                    h = sha256_text(ch)[:24]\n",
    "                    cid = f\"{h}__{base}__p{page}__c{i}\"\n",
    "                    meta = {\"source_document\": base, \"doctype\": doctype, \"page\": page}\n",
    "                    yield cid, ch, meta\n",
    "                    produced += 1\n",
    "                    if SAFE_INGEST and produced >= MAX_CHUNKS_TOTAL:\n",
    "                        return\n",
    "        else:\n",
    "            content = read_txt(p).strip()\n",
    "            if not content: \n",
    "                continue\n",
    "            for i, ch in enumerate(recursive_chunk(content, max_chars=chunk_size, overlap=overlap)):\n",
    "                h = sha256_text(ch)[:24]\n",
    "                cid = f\"{h}__{base}__c{i}\"\n",
    "                meta = {\"source_document\": base, \"doctype\": doctype}\n",
    "                yield cid, ch, meta\n",
    "                produced += 1\n",
    "                if SAFE_INGEST and produced >= MAX_CHUNKS_TOTAL:\n",
    "                    return\n",
    "\n",
    "def _index_vectors_check():\n",
    "    \"\"\"Quickly detect if the Pinecone index already contains vectors.\n",
    "\n",
    "    Returns:\n",
    "        True if a trivial query returns matches; False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        res = index.query(vector=[0.0]*VECTOR_DIM, top_k=1)\n",
    "        return bool(res.get(\"matches\"))\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def ingest_documents(paths, batch_size=BATCH_SIZE):\n",
    "    \"\"\"Chunk, embed, and upsert documents into Pinecone (with caps and skip-if-nonempty).\n",
    "\n",
    "    Args:\n",
    "        paths: Iterable of document file paths.\n",
    "        batch_size: Number of chunks to embed/upsert per batch.\n",
    "    \"\"\"\n",
    "    if SKIP_INGEST_IF_INDEX_NONEMPTY and _index_vectors_check():\n",
    "        print(\"[INGEST] Skipped (index already has vectors).\")\n",
    "        return\n",
    "\n",
    "    buffer_ids, buffer_texts, buffer_meta = [], [], []\n",
    "    total = 0\n",
    "    print(f\"[INGEST] starting… caps: pages={MAX_PDF_PAGES}, chunks={MAX_CHUNKS_TOTAL}, batch={BATCH_SIZE}\")\n",
    "\n",
    "    for cid, ch, meta in iter_doc_chunks(paths, chunk_size=1600, overlap=160):\n",
    "        buffer_ids.append(cid); buffer_texts.append(ch); buffer_meta.append(meta)\n",
    "        if len(buffer_texts) >= batch_size:\n",
    "            vecs = embed_texts(buffer_texts)\n",
    "            up = []\n",
    "            for _id, _vec, _meta, _txt in zip(buffer_ids, vecs, buffer_meta, buffer_texts):\n",
    "                m = dict(_meta); m.update({\"hash\": sha256_text(_txt), \"len\": len(_txt)})\n",
    "                up.append({\"id\": _id, \"values\": _vec, \"metadata\": m})\n",
    "            index.upsert(vectors=up)\n",
    "            total += len(up)\n",
    "            print(f\"[INGEST] Upserted total={total} (last batch={len(up)})\")\n",
    "            buffer_ids.clear(); buffer_texts.clear(); buffer_meta.clear()\n",
    "            time.sleep(0.05)\n",
    "\n",
    "    if buffer_texts:\n",
    "        vecs = embed_texts(buffer_texts)\n",
    "        up = []\n",
    "        for _id, _vec, _meta, _txt in zip(buffer_ids, vecs, buffer_meta, buffer_texts):\n",
    "            m = dict(_meta); m.update({\"hash\": sha256_text(_txt), \"len\": len(_txt)})\n",
    "            up.append({\"id\": _id, \"values\": _vec, \"metadata\": m})\n",
    "        index.upsert(vectors=up)\n",
    "        total += len(up)\n",
    "        print(f\"[INGEST] Upserted total={total} (last batch={len(up)})\")\n",
    "\n",
    "    print(f\"[INGEST] Done. Total chunks this run: {total}\")\n",
    "\n",
    "def pinecone_search(query, top_k=8, filter_meta=None):\n",
    "    \"\"\"Semantic search over the Pinecone index using a fresh query embedding.\n",
    "\n",
    "    Args:\n",
    "        query: Natural language query.\n",
    "        top_k: Number of results to return.\n",
    "        filter_meta: Optional metadata filter dict.\n",
    "\n",
    "    Returns:\n",
    "        Pinecone query response dict (with matches and metadata).\n",
    "    \"\"\"\n",
    "    qv = embed_texts([query])[0]\n",
    "    return index.query(vector=qv, top_k=top_k, include_metadata=True, filter=filter_meta or {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2447812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _is_429(err: Exception) -> bool:\n",
    "    \"\"\"Heuristic check if an Exception represents an HTTP 429 (Too Many Requests).\"\"\"\n",
    "    s = str(err).lower()\n",
    "    return \"429\" in s or \"too many requests\" in s\n",
    "\n",
    "\n",
    "def _retry_pytrends(call_fn, *, max_retries=5, base_sleep=1.0, jitter=0.35, escalate=1.8):\n",
    "    \"\"\"Retry wrapper with exponential backoff + jitter for pytrends calls.\n",
    "\n",
    "    Args:\n",
    "        call_fn: Zero-arg callable to execute.\n",
    "        max_retries: Max attempts.\n",
    "        base_sleep: Initial backoff in seconds.\n",
    "        jitter: Random jitter added to each delay.\n",
    "        escalate: Exponential multiplier per attempt.\n",
    "\n",
    "    Returns:\n",
    "        Result of call_fn if successful.\n",
    "\n",
    "    Raises:\n",
    "        The last exception after exhausting retries.\n",
    "    \"\"\"\n",
    "    attempt = 0\n",
    "    while True:\n",
    "        try:\n",
    "            return call_fn()\n",
    "        except Exception as e:\n",
    "            attempt += 1\n",
    "            if attempt >= max_retries:\n",
    "                raise\n",
    "            # sleep with backoff + jitter to avoid 429\n",
    "            delay = (base_sleep * (escalate ** (attempt - 1))) + random.random() * jitter\n",
    "            time.sleep(delay)\n",
    "\n",
    "def make_trends_client():\n",
    "    \"\"\"Create and return a configured pytrends TrendReq client, or None if mocked/unavailable.\n",
    "\n",
    "    Returns:\n",
    "        TrendReq instance or None.\n",
    "    \"\"\"\n",
    "    if MOCK_ANALYST or not PYTRENDS_AVAILABLE:\n",
    "        return None\n",
    "    try:\n",
    "        return TrendReq(\n",
    "            hl='en-US',\n",
    "            tz=330,\n",
    "            retries=None,         \n",
    "            backoff_factor=0,    \n",
    "            requests_args={\n",
    "                \"headers\": {\n",
    "                    \"User-Agent\": (\n",
    "                        \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 \"\n",
    "                        \"(KHTML, like Gecko) Chrome/120.0 Safari/537.36\"\n",
    "                    )\n",
    "                },\n",
    "                \"timeout\": (5, 15),\n",
    "            },\n",
    "        )\n",
    "    except TypeError:\n",
    "        # Fallback for older pytrends signatures\n",
    "        return TrendReq(hl='en-US', tz=330)\n",
    "\n",
    "\n",
    "def _mock_interest_over_time(keywords, periods=168, freq='H'):\n",
    "    \"\"\"Generate synthetic hourly interest time series for given keywords.\n",
    "\n",
    "    Args:\n",
    "        keywords: List of keyword strings.\n",
    "        periods: Number of time steps.\n",
    "        freq: Pandas frequency string (e.g., 'H').\n",
    "\n",
    "    Returns:\n",
    "        DataFrame indexed by datetime with one column per keyword and 'isPartial' flag.\n",
    "    \"\"\"\n",
    "    idx = pd.date_range(end=pd.Timestamp.now().floor('H'), periods=periods, freq=freq)\n",
    "    data = {}\n",
    "    for kw in keywords:\n",
    "        base = random.randint(20, 60)\n",
    "        noise = pd.Series([random.randint(-5, 5) for _ in range(periods)], index=idx).cumsum()\n",
    "        season = pd.Series([max(0, int(15*abs((i/10)))) for i in range(periods)], index=idx)\n",
    "        series = pd.Series(base, index=idx) + noise + season\n",
    "        series = series.clip(lower=0)\n",
    "        data[kw] = series\n",
    "    df = pd.DataFrame(data); df.index.name = \"datetime\"; df[\"isPartial\"] = False\n",
    "    return df\n",
    "\n",
    "def _mock_related_queries(keywords):\n",
    "    \"\"\"Return synthetic 'top' and 'rising' related query DataFrames for each keyword.\n",
    "\n",
    "    Args:\n",
    "        keywords: List of keyword strings.\n",
    "\n",
    "    Returns:\n",
    "        Dict[keyword] -> {\"top\": DataFrame, \"rising\": DataFrame}.\n",
    "    \"\"\"\n",
    "    mock = {}\n",
    "    for kw in keywords:\n",
    "        mock[kw] = {\n",
    "            \"top\": pd.DataFrame({\n",
    "                \"query\": [f\"{kw} price\", f\"{kw} review\", f\"{kw} specs\", f\"best alternative to {kw}\"],\n",
    "                \"value\": [100, 85, 77, 64]\n",
    "            }),\n",
    "            \"rising\": pd.DataFrame({\n",
    "                \"query\": [f\"{kw} discount\", f\"{kw} exchange offer\", f\"{kw} vs competitor\"],\n",
    "                \"value\": [800, 540, 420]\n",
    "            })\n",
    "        }\n",
    "    return mock\n",
    "\n",
    "def fetch_interest_over_time(pytrend, keywords, geo, timeframe, gprop):\n",
    "    \"\"\"Fetch Google Trends interest-over-time for keywords (or mock if offline/blocked).\n",
    "\n",
    "    Args:\n",
    "        pytrend: TrendReq client or None.\n",
    "        keywords: List of keywords.\n",
    "        geo: Country/region code (e.g., 'IN').\n",
    "        timeframe: Trends timeframe (e.g., 'now 7-d').\n",
    "        gprop: Google property ('', 'news', 'images', 'youtube', 'froogle').\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with interest indices per keyword and 'isPartial' column.\n",
    "    \"\"\"\n",
    "    if MOCK_ANALYST or pytrend is None:\n",
    "        return _mock_interest_over_time(keywords, periods=7*24, freq='H')\n",
    "\n",
    "    def _do():\n",
    "        pytrend.build_payload(kw_list=keywords, timeframe=timeframe, geo=geo, gprop=gprop)\n",
    "        time.sleep(1.2)\n",
    "        return pytrend.interest_over_time()\n",
    "\n",
    "    return _retry_pytrends(_do, max_retries=5, base_sleep=1.0, jitter=0.4, escalate=2.0)\n",
    "\n",
    "\n",
    "def fetch_related_queries(pytrend, keywords, geo, timeframe, gprop):\n",
    "    \"\"\"Fetch Google Trends related queries for keywords (or mock if offline/blocked).\n",
    "\n",
    "    Args:\n",
    "        pytrend: TrendReq client or None.\n",
    "        keywords: List of keywords.\n",
    "        geo: Region for payload.\n",
    "        timeframe: Trends timeframe.\n",
    "        gprop: Google property.\n",
    "\n",
    "    Returns:\n",
    "        Dict[keyword] -> {\"top\": DataFrame, \"rising\": DataFrame}.\n",
    "    \"\"\"\n",
    "    if MOCK_ANALYST or pytrend is None:\n",
    "        return _mock_related_queries(keywords)\n",
    "\n",
    "    def _do():\n",
    "        pytrend.build_payload(kw_list=keywords, timeframe=timeframe, geo=geo, gprop=gprop)\n",
    "        time.sleep(1.2)\n",
    "        return pytrend.related_queries()\n",
    "\n",
    "    return _retry_pytrends(_do, max_retries=5, base_sleep=1.0, jitter=0.4, escalate=2.0)\n",
    "\n",
    "\n",
    "def fetch_state_interest(pytrend, keywords, sub_geo, timeframe, gprop):\n",
    "    \"\"\"Fetch state-level Google Trends interest-over-time (or mock if offline/blocked).\n",
    "\n",
    "    Args:\n",
    "        pytrend: TrendReq client or None.\n",
    "        keywords: List of keywords.\n",
    "        sub_geo: Sub-region code (e.g., 'IN-GJ').\n",
    "        timeframe: Trends timeframe.\n",
    "        gprop: Google property.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with interest indices per keyword and 'isPartial' column.\n",
    "    \"\"\"\n",
    "    if MOCK_ANALYST or pytrend is None:\n",
    "        return _mock_interest_over_time(keywords, periods=7*24, freq='H')\n",
    "\n",
    "    def _do():\n",
    "        pytrend.build_payload(kw_list=keywords, timeframe=timeframe, geo=sub_geo, gprop=gprop)\n",
    "        time.sleep(1.2)\n",
    "        return pytrend.interest_over_time()\n",
    "\n",
    "    return _retry_pytrends(_do, max_retries=5, base_sleep=1.0, jitter=0.4, escalate=2.0)\n",
    "\n",
    "def fetch_realtime_trends(pytrend, geo=\"IN\"):\n",
    "    \"\"\"\n",
    "    Fetch country-level realtime trending searches from Google Trends, with safe fallbacks.\n",
    "\n",
    "    Behavior:\n",
    "      - If MOCK mode is active or `pytrend` is None, returns a small mock DataFrame (offline-friendly).\n",
    "      - Tries `pytrend.realtime_trending_searches(pn=geo)` first; if unavailable, falls back to\n",
    "        `pytrend.trending_searches(pn=\"india\")`.\n",
    "      - Wrapped in `_retry_pytrends` (exponential backoff + jitter) to avoid freezes on 429/temporary errors.\n",
    "\n",
    "    Args:\n",
    "        pytrend: An initialized `pytrends.request.TrendReq` client or `None` (mock/offline).\n",
    "        geo (str): Country code for realtime trends (e.g., \"IN\"). Ignored in mock mode.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Top realtime (or fallback) trending searches, with columns such as\n",
    "        'title', 'entity_names', and 'traffic' when available. If both live and fallback fail,\n",
    "        a mock DataFrame is returned when MOCK mode is on; otherwise, an empty DataFrame may be returned.\n",
    "\n",
    "    Notes:\n",
    "        - This function is optional; it's safe to call and will not halt the pipeline on rate limits.\n",
    "        - Use `include_realtime=True` in `run_market_analyst(...)` to attach these rows to the payload.\n",
    "    \"\"\"\n",
    "    if MOCK_ANALYST or pytrend is None:\n",
    "        # Reference offline-friendly mock\n",
    "        return pd.DataFrame({\n",
    "            \"title\": [\"Festive sale electronics\", \"iPhone 16 rumors\", \"Noise ANC Pro 2\", \"OLED TV deals\"],\n",
    "            \"entity_names\": [[\"sale\"], [\"iphone\"], [\"headphones\"], [\"tv\"]],\n",
    "            \"traffic\": [100000, 82000, 45000, 39000],\n",
    "        })\n",
    "    def _do():\n",
    "        try:\n",
    "            # Some pytrends builds have realtime; if not, fall back\n",
    "            df = pytrend.realtime_trending_searches(pn=geo)\n",
    "            return df\n",
    "        except Exception:\n",
    "            return pytrend.trending_searches(pn=\"india\")\n",
    "    return _retry_pytrends(_do, max_retries=5, base_sleep=1.0, jitter=0.4, escalate=2.0)\n",
    "\n",
    "\n",
    "def package_signals(iot_df, state_df, rq_top_df, city_hint=\"Surat\", state_code=\"IN-GJ\"):\n",
    "    \"\"\"Assemble a normalized market signal payload for downstream agents.\n",
    "\n",
    "    Args:\n",
    "        iot_df: Interest over time DataFrame (national).\n",
    "        state_df: Interest over time DataFrame (state proxy).\n",
    "        rq_top_df: Flattened top related queries DataFrame.\n",
    "        city_hint: Display city name for metadata.\n",
    "        state_code: Sub-region code (e.g., 'IN-GJ').\n",
    "\n",
    "    Returns:\n",
    "        Dict payload with 'market' and 'signals' keys.\n",
    "    \"\"\"\n",
    "    def top_keyword(df, window=-48):\n",
    "        sub = df.iloc[window:] if len(df) + window > 0 else df\n",
    "        cols = [c for c in sub.columns if c != \"isPartial\"]\n",
    "        means = sub[cols].mean().sort_values(ascending=False)\n",
    "        return [{\"keyword\": k, \"score\": float(v)} for k, v in means.items()]\n",
    "    payload = {\n",
    "        \"as_of\": pd.Timestamp.utcnow().isoformat() + \"Z\",\n",
    "        \"market\": {\"country\": \"IN\", \"state\": state_code, \"city_proxy\": city_hint},\n",
    "        \"signals\": {\n",
    "            \"interest_over_time_national\": top_keyword(iot_df),\n",
    "            \"interest_over_time_state\": top_keyword(state_df),\n",
    "            \"related_queries_top\": rq_top_df.head(50).to_dict(orient=\"records\")\n",
    "        }\n",
    "    }\n",
    "    return payload\n",
    "\n",
    "def run_market_analyst(keywords,geo=\"IN\",sub_geo=\"IN-GJ\",timeframe=\"now 7-d\",gprop=\"froogle\",mock=False,city_hint=\"Surat\",include_realtime=False):\n",
    "    \"\"\"End-to-end Trends fetch with automatic 429 fallback to mock data.\n",
    "\n",
    "    Args:\n",
    "        keywords: List of product keywords.\n",
    "        geo: Country/region code.\n",
    "        sub_geo: State/sub-region code (city proxy).\n",
    "        timeframe: Trends timeframe.\n",
    "        gprop: Google property.\n",
    "        mock: Force mock mode if True.\n",
    "        city_hint: City label for metadata packaging.\n",
    "\n",
    "    Returns:\n",
    "        Dict with a single key 'payload' containing packaged signals.\n",
    "    \"\"\"\n",
    "    global MOCK_ANALYST\n",
    "    MOCK_ANALYST = mock\n",
    "    pytrend = make_trends_client()\n",
    "\n",
    "    try:\n",
    "        iot_df  = fetch_interest_over_time(pytrend, keywords, geo, timeframe, gprop)\n",
    "        state_df = fetch_state_interest(pytrend, keywords, sub_geo, timeframe, gprop)\n",
    "        rq      = fetch_related_queries(pytrend, keywords, geo, timeframe, gprop)\n",
    "        rt_df   = None\n",
    "        if include_realtime:\n",
    "            try:\n",
    "                rt_df = fetch_realtime_trends(pytrend, geo=geo)\n",
    "            except Exception as e:\n",
    "                print(\"[WARN] realtime trends disabled:\", e)\n",
    "                rt_df = None\n",
    "    except Exception as e:\n",
    "        if not mock and _is_429(e):\n",
    "            print(\"[WARN] Google Trends rate-limited (429). Falling back to MOCK mode for this run.\")\n",
    "            MOCK_ANALYST = True\n",
    "            pytrend = None\n",
    "            iot_df  = fetch_interest_over_time(pytrend, keywords, geo, timeframe, gprop)\n",
    "            state_df = fetch_state_interest(pytrend, keywords, sub_geo, timeframe, gprop)\n",
    "            rq      = fetch_related_queries(pytrend, keywords, geo, timeframe, gprop)\n",
    "            rt_df   = fetch_realtime_trends(pytrend, geo=geo) if include_realtime else None\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    # flatten related queries\n",
    "    rows = []\n",
    "    for kw, parts in rq.items():\n",
    "        top_df = parts.get(\"top\")\n",
    "        if isinstance(top_df, pd.DataFrame):\n",
    "            for _, r in top_df.iterrows():\n",
    "                rows.append({\"keyword\": kw, \"query\": r[\"query\"], \"value\": int(r[\"value\"])})\n",
    "    rq_top_df = pd.DataFrame(rows).sort_values([\"keyword\", \"value\"], ascending=[True, False]).reset_index(drop=True)\n",
    "\n",
    "    payload = package_signals(iot_df, state_df, rq_top_df, city_hint=city_hint, state_code=sub_geo)\n",
    "\n",
    "    if include_realtime and isinstance(rt_df, pd.DataFrame):\n",
    "        payload.setdefault(\"signals\", {})[\"realtime_trends\"] = rt_df.head(20).to_dict(orient=\"records\")\n",
    "    else:\n",
    "        payload.setdefault(\"signals\", {})[\"realtime_trends\"] = []\n",
    "\n",
    "    iot_df.to_csv(os.path.join(ARTIFACT_DIR, \"interest_over_time_latest.csv\"))\n",
    "    state_df.to_csv(os.path.join(ARTIFACT_DIR, f\"interest_over_time_{sub_geo}_latest.csv\"))\n",
    "    rq_top_df.to_csv(os.path.join(ARTIFACT_DIR, \"related_queries_top_latest.csv\"), index=False)\n",
    "    return {\"payload\": payload}\n",
    "\n",
    "\n",
    "def market_signals_to_weights(payload):\n",
    "    \"\"\"Convert packaged market signals into normalized category weights (0..1).\n",
    "\n",
    "    Args:\n",
    "        payload: Dict as returned by package_signals/run_market_analyst.\n",
    "\n",
    "    Returns:\n",
    "        Dict category -> weight (e.g., {'mobiles': 1.0, 'laptops': 0.4, ...}).\n",
    "    \"\"\"\n",
    "    state_top = payload[\"signals\"].get(\"interest_over_time_state\", [])\n",
    "    if not state_top:\n",
    "        state_top = payload[\"signals\"].get(\"interest_over_time_national\", [])\n",
    "\n",
    "    def cat_for(kw):\n",
    "        k = kw.lower()\n",
    "        if any(x in k for x in [\"iphone\", \"galaxy\", \"mobile\", \"phone\"]): return \"mobiles\"\n",
    "        if any(x in k for x in [\"laptop\", \"macbook\"]): return \"laptops\"\n",
    "        if any(x in k for x in [\"headphone\", \"earbud\", \"audio\", \"anc\", \"soundbar\"]): return \"audio\"\n",
    "        if any(x in k for x in [\"gaming\", \"console\", \"ps5\", \"xbox\", \"nintendo\"]): return \"gaming\"\n",
    "        if any(x in k for x in [\"fridge\", \"air conditioner\", \"washing\", \"tv\", \"ac \"]): return \"appliances\"\n",
    "        return \"mobiles\"\n",
    "\n",
    "    bucket = {\"mobiles\":0.0,\"laptops\":0.0,\"audio\":0.0,\"gaming\":0.0,\"appliances\":0.0}\n",
    "    for item in state_top:\n",
    "        bucket[cat_for(item[\"keyword\"])] += float(item[\"score\"])\n",
    "    for rq in payload[\"signals\"].get(\"related_queries_top\", [])[:50]:\n",
    "        bucket[cat_for(rq[\"query\"])] += rq.get(\"value\", 0) * 0.2\n",
    "\n",
    "    mx = max(bucket.values()) if bucket else 1.0\n",
    "    if mx == 0: mx = 1.0\n",
    "    return {k: round(v/mx, 2) for k, v in bucket.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "282d09a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context_from_matches(matches, max_lines=20):\n",
    "    \"\"\"Summarize Pinecone matches into a compact citation string.\n",
    "\n",
    "    Args:\n",
    "        matches: Pinecone match list (with metadata).\n",
    "        max_lines: Max rows to include.\n",
    "\n",
    "    Returns:\n",
    "        Multi-line string of '[chunk_id] source p.page' entries.\n",
    "    \"\"\"\n",
    "    lines=[]\n",
    "    for m in matches[:max_lines]:\n",
    "        md=m.get(\"metadata\",{}); src=md.get(\"source_document\",\"unknown\"); page=md.get(\"page\",\"?\")\n",
    "        lines.append(\"[%s] %s p.%s\" % (m[\"id\"], src, page))\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def _first_json_block(s):\n",
    "    \"\"\"Extract the first JSON object from a string (handles optional ```json fences).\n",
    "\n",
    "    Args:\n",
    "        s: Raw model output string.\n",
    "\n",
    "    Returns:\n",
    "        The JSON substring if found, else None.\n",
    "    \"\"\"\n",
    "    if not s:\n",
    "        return None\n",
    "    fence = re.search(r\"```(?:json)?\\s*({.*?})\\s*```\", s, flags=re.S)\n",
    "    if fence:\n",
    "        return fence.group(1)\n",
    "    brace = re.search(r\"({.*})\", s, flags=re.S)\n",
    "    if brace:\n",
    "        return brace.group(1)\n",
    "    return None\n",
    "\n",
    "def parse_layout_json(text_or_obj):\n",
    "    \"\"\"Parse model output into a Python dict, tolerating fenced or extra text.\n",
    "\n",
    "    Args:\n",
    "        text_or_obj: Model response object or raw string.\n",
    "\n",
    "    Returns:\n",
    "        Dict parsed from JSON.\n",
    "\n",
    "    Raises:\n",
    "        Exception if no valid JSON can be extracted.\n",
    "    \"\"\"\n",
    "    if isinstance(text_or_obj, dict):\n",
    "        return text_or_obj\n",
    "    if hasattr(text_or_obj, \"text\"):\n",
    "        payload = text_or_obj.text\n",
    "    else:\n",
    "        payload = str(text_or_obj)\n",
    "    try:\n",
    "        return json.loads(payload)\n",
    "    except Exception:\n",
    "        cleaned = _first_json_block(payload)\n",
    "        if cleaned:\n",
    "            return json.loads(cleaned)\n",
    "        raise\n",
    "\n",
    "\n",
    "def strategist_generate_layout(city, floor_area_sqm, entry_points, trend_weights, top_k=12, corridor_min_m=1.2):\n",
    "    \"\"\"RAG-augmented layout planning: retrieve, prompt Gemini for JSON, validate, fallback.\n",
    "\n",
    "    Args:\n",
    "        city: Target city name.\n",
    "        floor_area_sqm: Total floor area in square meters.\n",
    "        entry_points: List of site entry point dicts.\n",
    "        trend_weights: Category weights (0..1).\n",
    "        top_k: Number of RAG chunks to retrieve.\n",
    "        corridor_min_m: Minimum corridor width requirement.\n",
    "\n",
    "    Returns:\n",
    "        LayoutPlan Pydantic model (with citations and optional fallback).\n",
    "    \"\"\"\n",
    "    matches = pinecone_search(\n",
    "        \"layout constraints for %s; NBC; lease; brand rules; fixtures\" % city,\n",
    "        top_k=top_k\n",
    "    ).get(\"matches\", [])\n",
    "\n",
    "    citations = [\n",
    "        {\"chunk_id\": m.get(\"id\"),\n",
    "         \"source_document\": m.get(\"metadata\", {}).get(\"source_document\"),\n",
    "         \"page\": m.get(\"metadata\", {}).get(\"page\")}\n",
    "        for m in matches\n",
    "    ]\n",
    "    retrieval_context = build_context_from_matches(matches)\n",
    "\n",
    "    schema_hint = {\n",
    "        \"site\": {\"city\": city, \"floor_area_sqm\": floor_area_sqm, \"dimensions_m\": {\"width\": 20.0, \"height\": 12.0}, \"entry_points\": entry_points},\n",
    "        \"zoning\": [{\"zone_id\":\"Z?\",\"name\":\"?\",\"priority\":0.0,\"area_sqm\":0.0,\"rect\":{\"x\":0.0,\"y\":0.0,\"w\":0.0,\"h\":0.0}}],\n",
    "        \"fixtures\": [{\"fixture_id\":\"?\",\"zone_id\":\"?\",\"x\":0.0,\"y\":0.0,\"w\":0.0,\"h\":0.0,\"rotation_deg\":0}],\n",
    "        \"paths\": {\"min_corridor_width_m\": corridor_min_m, \"corridors\":[{\"x\":0.0,\"y\":0.0,\"w\":0.0,\"h\":0.0}]},\n",
    "        \"constraints\": {\"brand_rules\":[],\"lease\":[],\"nbc_accessibility\":[]},\n",
    "        \"citations\": citations\n",
    "    }\n",
    "\n",
    "    user_prompt = (\n",
    "        \"You are the Layout Strategist for a premium electronics retailer.\\n\"\n",
    "        \"Use ONLY the retrieved document IDs and trend weights to produce a compliant conceptual layout.\\n\"\n",
    "        \"Return STRICT JSON with keys: site, zoning, fixtures, paths, constraints, citations.\\n\"\n",
    "        \"No prose. No markdown. JSON ONLY.\\n\\n\"\n",
    "        \"Retrieved chunks (IDs only):\\n%s\\n\\n\"\n",
    "        \"Inputs:\\nCity: %s\\nFloor area (sqm): %s\\nEntry points: %s\\n\"\n",
    "        \"Trend weights (0..1): %s\\nMin corridor width: %s m\\n\\n\"\n",
    "        \"JSON schema hint (shape only, fill values appropriately):\\n%s\"\n",
    "        % (retrieval_context, city, floor_area_sqm, entry_points, trend_weights, corridor_min_m, json.dumps(schema_hint))\n",
    "    )\n",
    "\n",
    "    model = genai.GenerativeModel(GEN_MODEL, generation_config=GEN_CONFIG)\n",
    "\n",
    "    last_err = None\n",
    "    for _ in range(3):\n",
    "        try:\n",
    "            resp = model.generate_content([user_prompt])\n",
    "            data = parse_layout_json(resp)\n",
    "            plan = LayoutPlan(**data)\n",
    "            if not plan.citations:\n",
    "                plan.citations = citations\n",
    "            return plan\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            time.sleep(0.8)\n",
    "\n",
    "    # FINAL FALLBACK (don’t crash the graph)\n",
    "    # Use a small baseline plan if the model response cannot be parsed.\n",
    "    plan = LayoutPlan(\n",
    "        site={\"city\": city, \"floor_area_sqm\": floor_area_sqm, \"dimensions_m\": {\"width\": 20.0, \"height\": 12.0}, \"entry_points\": entry_points},\n",
    "        zoning=[\n",
    "            {\"zone_id\":\"Z1\",\"name\":\"Mobiles\",\"priority\":0.9,\"area_sqm\":60.0,\"rect\":{\"x\":1.0,\"y\":6.5,\"w\":9.0,\"h\":4.5}},\n",
    "            {\"zone_id\":\"Z2\",\"name\":\"Laptops\",\"priority\":0.8,\"area_sqm\":50.0,\"rect\":{\"x\":1.0,\"y\":1.0,\"w\":9.0,\"h\":4.5}},\n",
    "            {\"zone_id\":\"Z3\",\"name\":\"Audio\",\"priority\":0.6,\"area_sqm\":35.0,\"rect\":{\"x\":11.0,\"y\":1.0,\"w\":8.0,\"h\":5.0}}\n",
    "        ],\n",
    "        fixtures=[\n",
    "            {\"fixture_id\":\"FX-Table-120x80\",\"zone_id\":\"Z1\",\"x\":2.0,\"y\":7.0,\"w\":1.2,\"h\":0.8},\n",
    "            {\"fixture_id\":\"FX-Table-120x80\",\"zone_id\":\"Z2\",\"x\":2.0,\"y\":2.0,\"w\":1.2,\"h\":0.8},\n",
    "            {\"fixture_id\":\"FX-Wall-Display\",\"zone_id\":\"Z3\",\"x\":11.0,\"y\":1.0,\"w\":0.5,\"h\":5.0}\n",
    "        ],\n",
    "        paths={\"min_corridor_width_m\": corridor_min_m, \"corridors\":[{\"x\":1.0,\"y\":5.7,\"w\":18.0,\"h\":1.2}]},\n",
    "        constraints={\"brand_rules\": [], \"lease\": [], \"nbc_accessibility\": []},\n",
    "        citations=citations\n",
    "    )\n",
    "    return plan\n",
    "\n",
    "\n",
    "def compliance_check(plan):\n",
    "    \"\"\"Apply lightweight rule checks (e.g., corridor widths) to a LayoutPlan.\n",
    "\n",
    "    Args:\n",
    "        plan: LayoutPlan instance.\n",
    "\n",
    "    Returns:\n",
    "        ComplianceReport with violations listed if any.\n",
    "    \"\"\"\n",
    "    min_w = plan.paths.get(\"min_corridor_width_m\", 1.2)\n",
    "    violations=[]\n",
    "    for c in plan.paths.get(\"corridors\", []):\n",
    "        width=min(c[\"w\"], c[\"h\"])\n",
    "        if width < min_w:\n",
    "            violations.append({\"type\":\"corridor_width\",\"required_m\":float(min_w),\"actual_m\":float(width),\"location\":c})\n",
    "    ok = len(violations)==0\n",
    "    return ComplianceReport(brand_rules_ok=True, lease_ok=True, nbc_ok=ok, violations=violations)\n",
    "\n",
    "def render_layout_png(plan, out_path):\n",
    "    \"\"\"Render a simple 2D diagram for the layout plan and save as PNG.\n",
    "\n",
    "    Args:\n",
    "        plan: LayoutPlan instance.\n",
    "        out_path: Output PNG path (written to disk).\n",
    "    \"\"\"\n",
    "    site=plan.site\n",
    "    dims=site.get(\"dimensions_m\") or {\"width\": math.sqrt(site.get(\"floor_area_sqm\", 200)),\n",
    "                                      \"height\": math.sqrt(site.get(\"floor_area_sqm\", 200))/1.5}\n",
    "    W=dims[\"width\"]; H=dims[\"height\"]\n",
    "    fig,ax=plt.subplots(figsize=(10,6)); ax.add_patch(Rectangle((0,0),W,H,fill=False,linewidth=2))\n",
    "    for e in site.get(\"entry_points\", []):\n",
    "        ax.add_patch(Rectangle((e[\"x\"], e[\"y\"]-0.1),0.2,0.2,fill=True)); ax.text(e[\"x\"]+0.25,e[\"y\"],\"Entry %s\" % e[\"id\"],va='center')\n",
    "    for z in plan.zoning:\n",
    "        r=z.rect; ax.add_patch(Rectangle((r.x,r.y),r.w,r.h,fill=False)); ax.text(r.x+r.w/2,r.y+r.h/2,z.name,ha='center',va='center',fontsize=9)\n",
    "    for fx in plan.fixtures:\n",
    "        ax.add_patch(Rectangle((fx.x,fx.y),fx.w,fx.h,fill=True)); ax.text(fx.x+fx.w/2,fx.y+fx.h/2,fx.fixture_id,ha='center',va='center',fontsize=6)\n",
    "    for c in plan.paths.get(\"corridors\", []):\n",
    "        ax.add_patch(Rectangle((c[\"x\"],c[\"y\"]),c[\"w\"],c[\"h\"],fill=False,linestyle='--')); ax.text(c[\"x\"]+c[\"w\"]/2,c[\"y\"]+c[\"h\"]/2,'Corridor',ha='center',va='center',fontsize=7)\n",
    "    ax.set_xlim(0,W); ax.set_ylim(0,H); ax.set_aspect('equal', adjustable='box'); ax.set_title(\"Conceptual Layout – %s\" % site.get('city',''))\n",
    "    ax.set_xlabel(\"Meters (X)\"); ax.set_ylabel(\"Meters (Y)\"); plt.tight_layout(); plt.savefig(out_path,dpi=150); plt.close(fig)\n",
    "\n",
    "def log_run_to_mlflow(city, trend_weights, plan, png_path, index_name):\n",
    "    \"\"\"Log parameters, metrics, and artifacts for a layout run to MLflow.\n",
    "\n",
    "    Args:\n",
    "        city: City label.\n",
    "        trend_weights: Dict of category weights.\n",
    "        plan: LayoutPlan instance.\n",
    "        png_path: Path to rendered PNG.\n",
    "        index_name: Pinecone index name (for traceability).\n",
    "    \"\"\"\n",
    "    mlflow.set_tracking_uri(\"http://20.75.92.162:5000/\")\n",
    "    mlflow.set_experiment(\"Team_7_Capstone_2_Architect_Copilot_Retail_Capstone\")\n",
    "    with mlflow.start_run(run_name=\"layout_%s\" % city):\n",
    "        mlflow.log_param(\"city\", city); mlflow.log_param(\"index\", index_name)\n",
    "        mlflow.log_param(\"embed_model\", EMBED_MODEL); mlflow.log_param(\"gen_model\", GEN_MODEL)\n",
    "        mlflow.log_param(\"corridor_min_m\", plan.paths.get(\"min_corridor_width_m\", 1.2))\n",
    "        for k,v in trend_weights.items(): mlflow.log_param(\"trend_%s\" % k, v)\n",
    "        comp = plan.compliance_report.model_dump() if plan.compliance_report else {}\n",
    "        mlflow.log_metric(\"nbc_ok\", int(comp.get(\"nbc_ok\", 0)))\n",
    "        mlflow.log_metric(\"violations_count\", len(comp.get(\"violations\", [])) if comp else 0)\n",
    "        json_path=os.path.join(\"./outputs\", \"layout_plan_%s.json\" % city)\n",
    "        with open(json_path,\"w\") as f: json.dump(plan.model_dump(), f, indent=2)\n",
    "        mlflow.log_artifact(json_path)\n",
    "        if os.path.exists(png_path): mlflow.log_artifact(png_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65db2248",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntryPoint(BaseModel):\n",
    "    \"\"\"Site entry definition used by the plan (position and width in meters).\"\"\"\n",
    "    id: str\n",
    "    x: float\n",
    "    y: float\n",
    "    width_m: float\n",
    "\n",
    "class ZoneRect(BaseModel):\n",
    "    \"\"\"Axis-aligned rectangle (x, y, w, h) in meters defining a zone's footprint.\"\"\"\n",
    "    x: float\n",
    "    y: float\n",
    "    w: float\n",
    "    h: float\n",
    "\n",
    "class Zone(BaseModel):\n",
    "    \"\"\"A functional area in the store with priority, area target, and bounding rect.\"\"\"\n",
    "    zone_id: str\n",
    "    name: str\n",
    "    priority: float\n",
    "    area_sqm: float\n",
    "    rect: ZoneRect\n",
    "\n",
    "class Fixture(BaseModel):\n",
    "    \"\"\"Placed fixture within a zone with dimensions and optional rotation.\"\"\"\n",
    "    fixture_id: str\n",
    "    zone_id: str\n",
    "    x: float\n",
    "    y: float\n",
    "    w: float\n",
    "    h: float\n",
    "    rotation_deg: float = 0\n",
    "\n",
    "class ComplianceReport(BaseModel):\n",
    "    \"\"\"Validation outcome for brand/lease/NBC checks with a list of violations.\"\"\"\n",
    "    brand_rules_ok: bool\n",
    "    lease_ok: bool\n",
    "    nbc_ok: bool\n",
    "    violations: List[Dict[str, Any]]\n",
    "\n",
    "class LayoutPlan(BaseModel):\n",
    "    \"\"\"Complete conceptual layout: site, zones, fixtures, paths, constraints, citations.\"\"\"\n",
    "    site: Dict[str, Any]\n",
    "    zoning: List[Zone]\n",
    "    fixtures: List[Fixture]\n",
    "    paths: Dict[str, Any]\n",
    "    constraints: Dict[str, Any]\n",
    "    citations: List[Dict[str, Any]]\n",
    "    compliance_report: Optional[ComplianceReport] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "397c5517",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AppState(TypedDict, total=False):\n",
    "    \"\"\"Graph state passed between nodes: inputs, intermediate signals, and outputs.\"\"\"\n",
    "    city: str\n",
    "    floor_area_sqm: float\n",
    "    entry_points: List[Dict[str, Any]]\n",
    "    trend_weights: Dict[str, float]\n",
    "    plan: Any\n",
    "    png_path: str\n",
    "    geo: str          # \"IN\"\n",
    "    sub_geo: str      # \"IN-GJ\" (state proxy for the city)\n",
    "    gprop: str        # \"\", \"news\", \"images\", \"youtube\", \"froogle\"\n",
    "    keywords: List[str]\n",
    "\n",
    "\n",
    "def node_market_analyst(state):\n",
    "    \"\"\"\n",
    "    LangGraph node: enriches AppState with market trend weights.\n",
    "\n",
    "    Pulls keywords/geo settings from `state` (with sensible defaults), calls\n",
    "    `run_market_analyst(...)` to fetch Google Trends based signals (auto-fallbacks\n",
    "    to mock on 429), converts signals to category weights via\n",
    "    `market_signals_to_weights(...)`, and stores them at `state[\"trend_weights\"]`.\n",
    "\n",
    "    Args:\n",
    "        state (AppState): Mutable pipeline state with optional keys:\n",
    "            - \"keywords\": List[str]\n",
    "            - \"geo\": str (e.g., \"IN\")\n",
    "            - \"sub_geo\": str (e.g., \"IN-TN\")\n",
    "            - \"timeframe\": str (e.g., \"now 7-d\")\n",
    "            - \"gprop\": str (e.g., \"froogle\")\n",
    "            - \"city\": str (used as city_hint)\n",
    "\n",
    "    Returns:\n",
    "        AppState: Same dict with `trend_weights` added.\n",
    "    \"\"\"\n",
    "    keywords = state.get(\"keywords\") or [\"iPhone 15\",\"Samsung Galaxy S24\",\"noise cancelling headphones\",\"gaming laptop\"]\n",
    "    geo = state.get(\"geo\", \"IN\")\n",
    "    sub_geo = state.get(\"sub_geo\", \"IN-GJ\")  # e.g., \"IN-TN\" for Chennai, \"IN-MH\" for Mumbai\n",
    "\n",
    "    out = run_market_analyst(\n",
    "        keywords=keywords,\n",
    "        geo=geo,\n",
    "        sub_geo=sub_geo,\n",
    "        timeframe=state.get(\"timeframe\", \"now 7-d\"),\n",
    "        gprop=state.get(\"gprop\", \"froogle\"),\n",
    "        mock=False,\n",
    "        city_hint=state.get(\"city\"),\n",
    "        include_realtime=True, \n",
    "    )\n",
    "    weights = market_signals_to_weights(out[\"payload\"])\n",
    "    state[\"trend_weights\"] = weights\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e0b5526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_strategist(state):\n",
    "    \"\"\"\n",
    "    LangGraph node: generates a compliant conceptual layout plan.\n",
    "\n",
    "    Uses `strategist_generate_layout(...)` with the city, floor area, entry points,\n",
    "    and `trend_weights` already present in `state`. Runs `compliance_check(...)`\n",
    "    on the result and saves the validated `LayoutPlan` at `state[\"plan\"]`.\n",
    "\n",
    "    Requires in `state`:\n",
    "        - \"city\": str\n",
    "        - \"floor_area_sqm\": float\n",
    "        - \"entry_points\": List[dict]\n",
    "        - \"trend_weights\": Dict[str, float]\n",
    "\n",
    "    Returns:\n",
    "        AppState: Same dict with `plan` (LayoutPlan) added.\n",
    "    \"\"\"\n",
    "    plan = strategist_generate_layout(\n",
    "        city=state[\"city\"],\n",
    "        floor_area_sqm=state[\"floor_area_sqm\"],\n",
    "        entry_points=state[\"entry_points\"],\n",
    "        trend_weights=state[\"trend_weights\"],\n",
    "        top_k=12,\n",
    "        corridor_min_m=1.2\n",
    "    )\n",
    "    plan.compliance_report = compliance_check(plan)\n",
    "    state[\"plan\"] = plan\n",
    "    return state\n",
    "\n",
    "def node_draftsman(state):\n",
    "    \"\"\"\n",
    "    LangGraph node: renders artifacts and logs the run.\n",
    "\n",
    "    Renders the `LayoutPlan` in `state[\"plan\"]` to a PNG under ./outputs/,\n",
    "    writes the layout JSON and trend weight JSON to ./outputs/, updates:\n",
    "        - `state[\"png_path\"]`\n",
    "        - `state[\"json_path\"]`\n",
    "        - `state[\"weights_path\"]`\n",
    "    and logs artifacts/params to MLflow via `log_run_to_mlflow(...)`.\n",
    "\n",
    "    Requires in `state`:\n",
    "        - \"city\": str\n",
    "        - \"plan\": LayoutPlan\n",
    "        - \"trend_weights\": Dict[str, float]\n",
    "\n",
    "    Side effects:\n",
    "        - Creates/overwrites files in ./outputs/\n",
    "        - Sends metrics/artifacts to MLflow\n",
    "\n",
    "    Returns:\n",
    "        AppState: Same dict with paths to generated files added.\n",
    "    \"\"\"\n",
    "    out_png = \"./outputs/layout_%s.png\" % state[\"city\"]\n",
    "    render_layout_png(state[\"plan\"], out_png)\n",
    "    state[\"png_path\"] = out_png\n",
    "\n",
    "    json_path = \"./outputs/layout_plan_%s.json\" % state[\"city\"]\n",
    "    try:\n",
    "        payload = state[\"plan\"].model_dump() if hasattr(state[\"plan\"], \"model_dump\") else state[\"plan\"]\n",
    "        with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(payload, f, indent=2)\n",
    "        state[\"json_path\"] = json_path\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] Failed to write plan JSON:\", e)\n",
    "\n",
    "    weights_path = \"./outputs/trend_weights_%s.json\" % state[\"city\"]\n",
    "    try:\n",
    "        with open(weights_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(state.get(\"trend_weights\", {}), f, indent=2)\n",
    "        state[\"weights_path\"] = weights_path\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] Failed to write weights JSON:\", e)\n",
    "    log_run_to_mlflow(state[\"city\"], state[\"trend_weights\"], state[\"plan\"], out_png, PINECONE_INDEX_NAME)\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30ecf609",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(AppState)\n",
    "graph.add_node(\"market_analyst\", node_market_analyst)\n",
    "graph.add_node(\"strategist\", node_strategist)\n",
    "graph.add_node(\"draftsman\", node_draftsman)\n",
    "\n",
    "graph.set_entry_point(\"market_analyst\")\n",
    "graph.add_edge(\"market_analyst\", \"strategist\")\n",
    "graph.add_edge(\"strategist\", \"draftsman\")\n",
    "graph.add_edge(\"draftsman\", END)\n",
    "\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1b0244e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x7e9dc80eb3d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f14f4222",
   "metadata": {},
   "outputs": [],
   "source": [
    "MOCK_ANALYST = False # False - real time, True - mocked up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "880fc976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index ready: blue-retail-docs\n"
     ]
    }
   ],
   "source": [
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "existing = [idx[\"name\"] for idx in pc.list_indexes()]\n",
    "if PINECONE_INDEX_NAME not in existing:\n",
    "    print(\"Creating Pinecone index...\")\n",
    "    pc.create_index(\n",
    "        name=PINECONE_INDEX_NAME,\n",
    "        dimension=VECTOR_DIM,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=PINECONE_CLOUD, region=PINECONE_REGION),\n",
    "    )\n",
    "    while True:\n",
    "        if pc.describe_index(PINECONE_INDEX_NAME).status[\"ready\"]:\n",
    "            break\n",
    "        time.sleep(2)\n",
    "index = pc.Index(PINECONE_INDEX_NAME)\n",
    "print(\"Index ready:\", PINECONE_INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a14e4037",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOC_PATHS = [\n",
    "    \"./docs/Blue_Retail_Brand_Book_v4.pdf\",\n",
    "    \"./docs/Fixture_Catalog_Q3_2025.pdf\",\n",
    "    \"./docs/National_Building_Code_Accessibility_Chapter.txt\",\n",
    "    \"./docs/Store_Leasing_Agreement_Surat.pdf\",\n",
    "    \"./docs/Retail_Design_Best_Practices.md\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "479d1a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INGEST] Skipped (index already has vectors).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages/pytrends/request.py:260: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(False)\n",
      "/home/zadmin/Desktop/test/GAAI-B5-GCP/genai/lib/python3.11/site-packages/pytrends/request.py:260: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] realtime trends disabled: The request failed: Google returned a response with code 404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/10 03:56:52 INFO mlflow.tracking.fluent: Experiment with name 'Team_7_Capstone_2_Architect_Copilot_Retail_Capstone' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run layout_Surat at: http://20.75.92.162:5000/#/experiments/196695771660628660/runs/971f3f5e768f4d199dff3bcab962fba2\n",
      "🧪 View experiment at: http://20.75.92.162:5000/#/experiments/196695771660628660\n",
      "Trend weights: {'mobiles': 1.0, 'laptops': 0.0, 'audio': 0.03, 'gaming': 0.0, 'appliances': 0.12}\n",
      "PNG saved: ./outputs/layout_Surat.png\n",
      "Plan JSON saved.\n"
     ]
    }
   ],
   "source": [
    "ingest_documents(DOC_PATHS)\n",
    "\n",
    "initial_state = {\n",
    "    \"city\": \"Surat\",\n",
    "    \"floor_area_sqm\": 240.0,\n",
    "    \"entry_points\": [{\"id\":\"E1\",\"x\":0.0,\"y\":6.0,\"width_m\":2.4}],\n",
    "    \"keywords\": [\"iPhone 15\", \"OnePlus 12\", \"Bluetooth headphones\", \"OLED TV\"],\n",
    "    \"geo\": \"IN\",\n",
    "    \"sub_geo\": \"IN-GJ\",    \n",
    "    # \"timeframe\": \"now 7-d\",\n",
    "    # \"gprop\": \"froogle\",\n",
    "}\n",
    "\n",
    "final_state = app.invoke(initial_state)\n",
    "\n",
    "print(\"Trend weights:\", final_state.get(\"trend_weights\"))\n",
    "print(\"PNG saved:\", final_state.get(\"png_path\"))\n",
    "print(\"Plan JSON saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23bf100",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
